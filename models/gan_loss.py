import torch
from torch import nn
from torchvision.models.vgg import vgg19


class GeneratorLoss(nn.Module):
	def __init__(self, args):
		super(GeneratorLoss, self).__init__()
		# note that vgg is for RGB image, hence not compatible with gray-scale
		self.vgg = vgg19(pretrained=True)
		self.loss_network = nn.Sequential(*list(self.vgg.features)[:35]).eval()
		for param in self.loss_network.parameters():
			param.requires_grad = False
		# average over all the pixels in the batch
		self.mse_loss = nn.MSELoss(reduction='mean')
		self.tv_loss = TVLoss()
		self.bce_loss = nn.BCELoss(reduction='mean')

		self.adversarial_weight = args.gamma
		self.perception_weight = args.sigma

	def forward(self, sr_probs, sr_images, hr_images):
		"""

		:param sr_probs: probability of generated fake image being original, [batch_size], as generator, we want to
						maximize this probability
		:param sr_images: fake image generated by generator, [batch_size, n_channels, height, width]
		:param hr_images: original high resolution image, [batch_size, n_channels, height, width]
		:return:
		"""
		cur_batch_size = sr_probs.size()[0]

		# for generator, we want the fake images to be true
		real_label = torch.full((cur_batch_size,), 1)
		if torch.cuda.is_available():
			real_label = real_label.cuda()

		# Adversarial Loss, per sample, we want to push sr_probs higher
		adversarial_loss = self.bce_loss(sr_probs.view(-1), real_label)
		# Mse Loss, per sample per pixel
		mse_loss = self.mse_loss(sr_images, hr_images)
		# Perception Loss, per sample

		# sr_feature_map = self.loss_network(sr_images)

		perception_loss = self.mse_loss(self.loss_network(sr_images), self.loss_network(hr_images))

		return mse_loss + self.adversarial_weight * adversarial_loss + self.perception_weight * perception_loss, \
		       adversarial_loss, mse_loss, perception_loss

class TVLoss(nn.Module):
	def __init__(self, tv_loss_weight=1):
		super(TVLoss, self).__init__()
		self.tv_loss_weight = tv_loss_weight

	def forward(self, x):
		batch_size = x.size()[0]
		h_x = x.size()[2]
		w_x = x.size()[3]
		count_h = self.tensor_size(x[:, :, 1:, :])
		count_w = self.tensor_size(x[:, :, :, 1:])
		h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()
		w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()
		return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size

	@staticmethod
	def tensor_size(t):
		return t.size()[1] * t.size()[2] * t.size()[3]

if __name__ == "__main__":
	g_loss = GeneratorLoss()
	print(g_loss)
